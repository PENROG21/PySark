{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN24dOqW1DUXhLZLMSh20hQ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/PENROG21/PySpark/blob/main/SQL_Pyspark.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L2gB9tKtNRgl",
        "outputId": "a3674e9a-0cd9-4608-cf31-c23af07e2284"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pyspark in /usr/local/lib/python3.11/dist-packages (3.5.4)\n",
            "Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.11/dist-packages (from pyspark) (0.10.9.7)\n"
          ]
        }
      ],
      "source": [
        "!pip install pyspark"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Пример использования DataFrame API\n",
        "\n",
        "### **Описание задачи**\n",
        "\n",
        "Предположим, у вас есть JSON файл с информацией о людях. Вам нужно прочитать эти данные, выполнить различные операции, такие как фильтрация, группировка и агрегация, а затем сохранить результат в формате CSV."
      ],
      "metadata": {
        "id": "m5O_nXUgP0h5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.functions import col\n",
        "\n",
        "# Создание SparkSession\n",
        "spark = SparkSession.builder.appName(\"DataFrameAPIExample\").getOrCreate()\n",
        "\n",
        "# Чтение данных из JSON файла\n",
        "df = spark.read.json(\"people.json\")\n",
        "\n",
        "# Фильтрация данных\n",
        "filtered_df = df.filter(col(\"age\") > 30)\n",
        "\n",
        "# Группировка и агрегация данных\n",
        "grouped_df = df.groupBy(\"department\").agg({\"age\": \"avg\", \"name\": \"count\"}).withColumnRenamed(\"avg(age)\", \"avg_age\").withColumnRenamed(\"count(name)\", \"count\")\n",
        "\n",
        "# Сортировка данных\n",
        "sorted_df = grouped_df.orderBy(col(\"count\").desc())\n",
        "\n",
        "# Показ результатов\n",
        "filtered_df.show()\n",
        "sorted_df.show()\n",
        "\n",
        "# Сохранение результирующего DataFrame в CSV файл\n",
        "sorted_df.write.csv(\"output.csv\", header=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BqotvtcBNlRK",
        "outputId": "07f25c69-9127-4b49-b24a-7ef5cc36a802"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------------+---+----------+----+\n",
            "|_corrupt_record|age|department|name|\n",
            "+---------------+---+----------+----+\n",
            "|           NULL| 35|        HR|Jane|\n",
            "|           NULL| 40|   Finance|Mark|\n",
            "+---------------+---+----------+----+\n",
            "\n",
            "+-----------+-----+-------+\n",
            "| department|count|avg_age|\n",
            "+-----------+-----+-------+\n",
            "|         HR|    2|   32.5|\n",
            "|    Finance|    2|   32.5|\n",
            "|Engineering|    1|   23.0|\n",
            "|       NULL|    0|   NULL|\n",
            "+-----------+-----+-------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Таким образом, как такового SQL нету. То есть есть SQL-подобные функции, но их предоставляет сам Spark."
      ],
      "metadata": {
        "id": "dEKI_-8ZP_J8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Теперь давайте посмотрим на то, как работает \"оригинальный SQL\" в PySpark.\n",
        "\n",
        "### Описание задачи\n",
        "Предположим, у вас есть два JSON файла: один с информацией о людях, а другой с информацией о департаментах. Вам нужно прочитать эти данные, зарегистрировать их как временные таблицы, выполнить JOIN-запрос и сохранить результат в формате CSV."
      ],
      "metadata": {
        "id": "wYY0GK34QCJv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "\n",
        "# Создание SparkSession\n",
        "spark = SparkSession.builder.appName(\"SQLAPIExample\").getOrCreate()\n",
        "\n",
        "# Чтение данных из JSON файлов\n",
        "people_df = spark.read.json(\"/content/sample_data/people.json\")\n",
        "departments_df = spark.read.json(\"/content/sample_data/departments.json\")\n",
        "\n",
        "# Регистрация DataFrame как временные таблицы\n",
        "people_df.createOrReplaceTempView(\"people\")\n",
        "departments_df.createOrReplaceTempView(\"departments\")\n",
        "\n",
        "# Выполнение JOIN-запроса с использованием SQL\n",
        "join_df = spark.sql(\"\"\"\n",
        "SELECT p.name, p.age, d.department_name\n",
        "FROM people p\n",
        "JOIN departments d\n",
        "ON p.department_id = d.id\n",
        "\"\"\")\n",
        "\n",
        "# Показ результатов\n",
        "join_df.show()\n",
        "\n",
        "# Сохранение результирующего DataFrame в CSV файл\n",
        "join_df.write.csv(\"output.csv\", header=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 547
        },
        "id": "7d0ZpQr9QKxA",
        "outputId": "0514704f-47ac-4928-a03c-91d27c6e85bc"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AnalysisException",
          "evalue": "[UNRESOLVED_COLUMN.WITH_SUGGESTION] A column or function parameter with name `p`.`department_id` cannot be resolved. Did you mean one of the following? [`p`.`department`, `d`.`department_name`, `p`.`name`, `p`.`age`, `d`.`id`].; line 5 pos 3;\n'Project ['p.name, 'p.age, 'd.department_name]\n+- 'Join Inner, ('p.department_id = id#166L)\n   :- SubqueryAlias p\n   :  +- SubqueryAlias people\n   :     +- View (`people`, [_corrupt_record#148,age#149L,department#150,name#151])\n   :        +- Relation [_corrupt_record#148,age#149L,department#150,name#151] json\n   +- SubqueryAlias d\n      +- SubqueryAlias departments\n         +- View (`departments`, [_corrupt_record#164,department_name#165,id#166L])\n            +- Relation [_corrupt_record#164,department_name#165,id#166L] json\n",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAnalysisException\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-ec2954891944>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;31m# Выполнение JOIN-запроса с использованием SQL\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m join_df = spark.sql(\"\"\"\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0mSELECT\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdepartment_name\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0mFROM\u001b[0m \u001b[0mpeople\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pyspark/sql/session.py\u001b[0m in \u001b[0;36msql\u001b[0;34m(self, sqlQuery, args, **kwargs)\u001b[0m\n\u001b[1;32m   1629\u001b[0m                     \u001b[0;34m[\u001b[0m\u001b[0m_to_java_column\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1630\u001b[0m                 )\n\u001b[0;32m-> 1631\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jsparkSession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msql\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msqlQuery\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlitArgs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1632\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1633\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1320\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1321\u001b[0m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1322\u001b[0;31m         return_value = get_return_value(\n\u001b[0m\u001b[1;32m   1323\u001b[0m             answer, self.gateway_client, self.target_id, self.name)\n\u001b[1;32m   1324\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pyspark/errors/exceptions/captured.py\u001b[0m in \u001b[0;36mdeco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m    183\u001b[0m                 \u001b[0;31m# Hide where the exception came from that shows a non-Pythonic\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m                 \u001b[0;31m# JVM exception message.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 185\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mconverted\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    186\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m                 \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAnalysisException\u001b[0m: [UNRESOLVED_COLUMN.WITH_SUGGESTION] A column or function parameter with name `p`.`department_id` cannot be resolved. Did you mean one of the following? [`p`.`department`, `d`.`department_name`, `p`.`name`, `p`.`age`, `d`.`id`].; line 5 pos 3;\n'Project ['p.name, 'p.age, 'd.department_name]\n+- 'Join Inner, ('p.department_id = id#166L)\n   :- SubqueryAlias p\n   :  +- SubqueryAlias people\n   :     +- View (`people`, [_corrupt_record#148,age#149L,department#150,name#151])\n   :        +- Relation [_corrupt_record#148,age#149L,department#150,name#151] json\n   +- SubqueryAlias d\n      +- SubqueryAlias departments\n         +- View (`departments`, [_corrupt_record#164,department_name#165,id#166L])\n            +- Relation [_corrupt_record#164,department_name#165,id#166L] json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Думаю, по коду и комментариям все понятно.\n",
        "\n",
        "*   Создаем объект SparkSession.\n",
        "*   Читаем JSON файлы в DataFrame.\n",
        "*   Регистрируем DataFrame как временные таблицы для выполнения SQL-запросов.\n",
        "*   Выполняем SQL-запрос для соединения таблиц по идентификатору департамента.\n",
        "*   Сохраняем результат в CSV файл.\n"
      ],
      "metadata": {
        "id": "FpXEoiVHQVY9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# JOIN"
      ],
      "metadata": {
        "id": "R8VYT79LRg1E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "\n",
        "# Создание SparkSession\n",
        "spark = SparkSession.builder.appName(\"JoinExamples\").getOrCreate()\n",
        "\n",
        "# Пример данных для DataFrame people\n",
        "people_data = [\n",
        "    (\"John\", 30, 1),\n",
        "    (\"Doe\", 25, 2),\n",
        "    (\"Jane\", 35, 1),\n",
        "    (\"Mark\", 40, 2),\n",
        "    (\"Smith\", 23, 3)\n",
        "]\n",
        "people_columns = [\"name\", \"age\", \"department_id\"]\n",
        "people_df = spark.createDataFrame(data=people_data, schema=people_columns)\n",
        "\n",
        "# Пример данных для DataFrame departments\n",
        "departments_data = [\n",
        "    (1, \"HR\"),\n",
        "    (2, \"Finance\"),\n",
        "    (3, \"Engineering\"),\n",
        "    (4, \"Marketing\")\n",
        "]\n",
        "departments_columns = [\"id\", \"department_name\"]\n",
        "departments_df = spark.createDataFrame(data=departments_data, schema=departments_columns)\n",
        "\n",
        "# Показ данных\n",
        "people_df.show()\n",
        "departments_df.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SWdp1eIRRjA_",
        "outputId": "c5d2b85b-7a15-40c1-abd5-2762f0f84db2"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+---+-------------+\n",
            "| name|age|department_id|\n",
            "+-----+---+-------------+\n",
            "| John| 30|            1|\n",
            "|  Doe| 25|            2|\n",
            "| Jane| 35|            1|\n",
            "| Mark| 40|            2|\n",
            "|Smith| 23|            3|\n",
            "+-----+---+-------------+\n",
            "\n",
            "+---+---------------+\n",
            "| id|department_name|\n",
            "+---+---------------+\n",
            "|  1|             HR|\n",
            "|  2|        Finance|\n",
            "|  3|    Engineering|\n",
            "|  4|      Marketing|\n",
            "+---+---------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Внутреннее соединение (Inner Join)\n",
        "Внутреннее соединение возвращает только те строки, которые имеют совпадающие значения в обеих таблицах."
      ],
      "metadata": {
        "id": "8e52AE5FRofJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Внутреннее соединение\n",
        "inner_join_df = people_df.join(departments_df, people_df.department_id == departments_df.id, \"inner\")\n",
        "inner_join_df.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "beeOuzJGRlXb",
        "outputId": "674954c5-e6fa-49e8-eb45-2da4a6e11899"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+---+-------------+---+---------------+\n",
            "| name|age|department_id| id|department_name|\n",
            "+-----+---+-------------+---+---------------+\n",
            "| John| 30|            1|  1|             HR|\n",
            "| Jane| 35|            1|  1|             HR|\n",
            "|  Doe| 25|            2|  2|        Finance|\n",
            "| Mark| 40|            2|  2|        Finance|\n",
            "|Smith| 23|            3|  3|    Engineering|\n",
            "+-----+---+-------------+---+---------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Левое внешнее соединение (Left Outer Join)\n",
        "Левое внешнее соединение возвращает все строки из левой таблицы и соответствующие строки из правой таблицы. Если соответствия нет, возвращаются NULL значения для столбцов правой таблицы."
      ],
      "metadata": {
        "id": "PWIN2wnMRw5k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Левое внешнее соединение\n",
        "left_outer_join_df = people_df.join(departments_df, people_df.department_id == departments_df.id, \"left_outer\")\n",
        "left_outer_join_df.show()"
      ],
      "metadata": {
        "id": "Aubz8zCiRtgc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Правое внешнее соединение (Right Outer Join)\n",
        "Правое внешнее соединение возвращает все строки из правой таблицы и соответствующие строки из левой таблицы. Если соответствия нет, возвращаются NULL значения для столбцов левой таблицы."
      ],
      "metadata": {
        "id": "XPVfnHIGR6ZJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Правое внешнее соединение\n",
        "right_outer_join_df = people_df.join(departments_df, people_df.department_id == departments_df.id, \"right_outer\")\n",
        "right_outer_join_df.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z83z199CR8lc",
        "outputId": "39232d89-7790-415a-cad0-ad6893791e8b"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+----+-------------+---+---------------+\n",
            "| name| age|department_id| id|department_name|\n",
            "+-----+----+-------------+---+---------------+\n",
            "| Jane|  35|            1|  1|             HR|\n",
            "| John|  30|            1|  1|             HR|\n",
            "| Mark|  40|            2|  2|        Finance|\n",
            "|  Doe|  25|            2|  2|        Finance|\n",
            "|Smith|  23|            3|  3|    Engineering|\n",
            "| NULL|NULL|         NULL|  4|      Marketing|\n",
            "+-----+----+-------------+---+---------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Полное внешнее соединение (Full Outer Join)\n",
        "Полное внешнее соединение возвращает все строки, когда есть совпадение в одной из таблиц. Строки без совпадений в обеих таблицах будут иметь NULL значения для столбцов из другой таблицы."
      ],
      "metadata": {
        "id": "0tWjLqJmR95O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "full_outer_join_df = people_df.join(departments_df, people_df.department_id == departments_df.id, \"outer\") full_outer_join_df.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        },
        "id": "xT6-PFeVR_hU",
        "outputId": "85ed26bd-4d13-49e9-a320-fa72a3a43cea"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "invalid syntax (<ipython-input-13-c4ac1b22b3fe>, line 1)",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-13-c4ac1b22b3fe>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    full_outer_join_df = people_df.join(departments_df, people_df.department_id == departments_df.id, \"outer\") full_outer_join_df.show()\u001b[0m\n\u001b[0m                                                                                                               ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Полное перекрестное соединение (Cross Join)\n",
        "Полное перекрестное соединение возвращает декартово произведение строк обеих таблиц.\n",
        "\n"
      ],
      "metadata": {
        "id": "kJa8JzV4SMoE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cross_join_df = people_df.crossJoin(departments_df)\n",
        "\n",
        "cross_join_df.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TtOyXSVASNfQ",
        "outputId": "90f2b994-a9cb-4535-e723-1d1373afbf64"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+---+-------------+---+---------------+\n",
            "| name|age|department_id| id|department_name|\n",
            "+-----+---+-------------+---+---------------+\n",
            "| John| 30|            1|  1|             HR|\n",
            "| John| 30|            1|  2|        Finance|\n",
            "|  Doe| 25|            2|  1|             HR|\n",
            "|  Doe| 25|            2|  2|        Finance|\n",
            "| John| 30|            1|  3|    Engineering|\n",
            "| John| 30|            1|  4|      Marketing|\n",
            "|  Doe| 25|            2|  3|    Engineering|\n",
            "|  Doe| 25|            2|  4|      Marketing|\n",
            "| Jane| 35|            1|  1|             HR|\n",
            "| Jane| 35|            1|  2|        Finance|\n",
            "| Mark| 40|            2|  1|             HR|\n",
            "| Mark| 40|            2|  2|        Finance|\n",
            "|Smith| 23|            3|  1|             HR|\n",
            "|Smith| 23|            3|  2|        Finance|\n",
            "| Jane| 35|            1|  3|    Engineering|\n",
            "| Jane| 35|            1|  4|      Marketing|\n",
            "| Mark| 40|            2|  3|    Engineering|\n",
            "| Mark| 40|            2|  4|      Marketing|\n",
            "|Smith| 23|            3|  3|    Engineering|\n",
            "|Smith| 23|            3|  4|      Marketing|\n",
            "+-----+---+-------------+---+---------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Соединение с использованием условия (Join with Condition)\n",
        "Соединение с использованием условия позволяет задать более сложные условия соединения."
      ],
      "metadata": {
        "id": "7nwEeQCPSSvV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "condition_join_df = people_df.join(departments_df, (people_df.department_id == departments_df.id) &\n",
        " (people_df.age > 30), \"inner\")\n",
        "condition_join_df.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WGBIrKDfSUyg",
        "outputId": "ed022ef7-a841-47b0-ed54-89d984400d1d"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----+---+-------------+---+---------------+\n",
            "|name|age|department_id| id|department_name|\n",
            "+----+---+-------------+---+---------------+\n",
            "|Jane| 35|            1|  1|             HR|\n",
            "|Mark| 40|            2|  2|        Finance|\n",
            "+----+---+-------------+---+---------------+\n",
            "\n"
          ]
        }
      ]
    }
  ]
}